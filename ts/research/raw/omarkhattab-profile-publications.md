---
title: "Omar Khattab - Academic Profile and Publications List"
url: "https://omarkhattab.com"
date_fetched: "2026-02-16"
---

Title: Omar Khattab

URL Source: https://omarkhattab.com/

Published Time: Fri, 06 Feb 2026 19:06:28 GMT

Markdown Content:
Omar Khattab
===============

[Omar Khattab](https://omarkhattab.com/)
========================================

![Image 1: Omar](https://omarkhattab.com/aZQB6U4b_400x400.jpg)
okhattab@mit.edu

[Curriculum Vitae](https://omarkhattab.com/okhattab_cv.pdf)

[Google Scholar](https://scholar.google.com/citations?user=Lwr5ozgAAAAJ&hl=en)

[GitHub](https://github.com/okhat)

[Twitter](https://twitter.com/lateinteraction)

I’m an Assistant Professor at MIT EECS and a member of CSAIL.

I study Natural Language Processing (NLP) and AI systems, seeking to answer questions like: How do we program intelligent software systems that are partly specified in natural language, that process natural language at scale, and whose quality and cost can be optimized using language models?

To answer these questions, my research develops new algorithms and abstractions for [declarative AI programming](https://arxiv.org/abs/2310.03714) and for composing [retrieval](https://arxiv.org/abs/2004.12832) and [reasoning](http://ai.stanford.edu/blog/retrieval-based-NLP/). This creates systems that [leverage massive text corpora](https://arxiv.org/abs/2101.00436) to [craft knowledgeable](https://arxiv.org/abs/2212.14024) responses [efficiently](https://arxiv.org/abs/2205.09707) and [transparently](https://hai.stanford.edu/news/moderate-proposal-radically-better-ai-powered-web-search).

I received my Ph.D. in Computer Science from Stanford, where I was advised by [Matei Zaharia](https://cs.stanford.edu/~matei/) and [Christopher Potts](https://web.stanford.edu/~cgpotts/) and was part of [Stanford NLP](https://nlp.stanford.edu/). During my Ph.D., I was generously supported by the Apple Scholars in AI/ML PhD Fellowship. After my Ph.D., I worked as a Research Scientist at Databricks.

* * *

Research
========

My research spans two overarching directions, consolidated in two influential open-source research systems, each downloaded millions of times a month.

[![Image 2](https://omarkhattab.com/DSPy8.png)](http://dspy.ai/)[![Image 3](https://omarkhattab.com/colbertofficial.png)](https://github.com/stanford-futuredata/ColBERT)

### I) Building Reliable AI Systems with Language Models

I built the **[DSPy framework](http://dspy.ai/)**, a programming model for declaratively expressing and automatically optimizing _Natural Language Programs_, i.e. modular software systems that use natural language to specify parts of their behavior. In this line of work, my research develops:

**Natural Language Programs** and their abstractions & optimizers, as in [DSPy](https://arxiv.org/abs/2310.03714) (ICLR’24 Spotlight) and its predecessor [DSP](https://arxiv.org/abs/2212.14024). It includes state-of-the-art systems like [STORM](https://arxiv.org/abs/2402.14207) (NAACL’24), [IReRa](https://arxiv.org/abs/2401.12178), [PATH](https://arxiv.org/abs/2406.11706), and [PAPILLON](https://arxiv.org/abs/2410.17127) (NAACL’25) and optimizers like [GEPA](https://arxiv.org/abs/2507.19457), [MIPRO](https://arxiv.org/abs/2406.11695) (EMNLP’24), [BetterTogether](https://arxiv.org/abs/2407.10930) (EMNLP’24).

**Retrieval-based NLP Systems** like [ColBERT-QA](https://arxiv.org/abs/2007.00814) (TACL’21), [Baleen](https://arxiv.org/abs/2101.00436) (NeurIPS’21 Spotlight), [Hindsight](https://arxiv.org/abs/2110.07752) (ICLR’22), and [ARES](https://arxiv.org/abs/2311.09476) (NAACL’24).

### II) Developing Effective & Efficient Retrieval Models

I built the **[ColBERT retrieval model](https://github.com/stanford-futuredata/ColBERT)**, which has been central to the development of the modern landscape of information retrieval. In this line of work, my research develops:

**Retrieval Models** like [ColBERT](https://arxiv.org/abs/2004.12832) (SIGIR’20), [ColBERTv2](https://arxiv.org/abs/2112.01488) (NAACL’22), and [UDAPDR](https://arxiv.org/abs/2303.00807) (EMNLP’23).

**Scalable Retrieval Infrastructure** like [PLAID](https://arxiv.org/abs/2205.09707) (CIKM’22), [WARP](https://arxiv.org/abs/2501.17788) (SIGIR’25 Best Paper), and [DeepImpact](https://arxiv.org/abs/2104.12016) (SIGIR’21).

* * *

Papers
======

**Recursive Language Models**

 A Zhang, T Kraska, O Khattab

**Preprint 2025** | [paper](https://arxiv.org/abs/2512.24601)

**GEPA: Reflective Prompt Evolution Can Outperform Reinforcement Learning**

 LA Agrawal, S Tan, D Soylu, N Ziems, …, D Klein, M Zaharia, O Khattab

**ICLR 2026 (Oral)** | [paper](https://arxiv.org/abs/2507.19457)

**Reasoning-Intensive Regression**

 D Tchuindjo, O Khattab

**Preprint 2025** | [paper](https://arxiv.org/abs/2508.21762)

**WARP: An Efficient Engine for Multi-Vector Retrieval**

 JL Scheerer, M Zaharia, C Potts, G Alonso, O Khattab

**SIGIR 2025**(Best Paper Award) | [paper](https://arxiv.org/abs/2501.17788)

**FreshStack: Building Realistic Benchmarks for Evaluating Retrieval on Technical Documents**

 N Thakur, J Lin, S Havens, M Carbin, O Khattab, A Drozdov 

**NeurIPS 2025** | [paper](https://arxiv.org/abs/2504.13128)

**Multi-module GRPO: Composing Policy Gradients and Prompt Optimization for Language Model Programs**

 N Ziems, D Soylu, L A Agrawal, I Miller, L Lai, …, C Potts, O Khattab

**Tech Report 2025** | [paper](https://www.arxiv.org/abs/2508.04660)

**LangProBe: a Language Programs Benchmark**

 S Tan, LA Agrawal, A Singhvi, L Lai, …, O Khattab, K Sen, M Zaharia 

**EMNLP 2025 Findings** | [paper](https://arxiv.org/abs/2502.20315)

**Drowning in Documents: Consequences of Scaling Reranker Inference**

 M Jacob, E Lindgren, M Zaharia, M Carbin, O Khattab, A Drozdov 

**ReNeuIR 2025** | [paper](https://arxiv.org/abs/2411.11767)

**PAPILLON: PrivAcy Preservation from Internet-based and Local Language MOdel ENsembles**

 L Siyan, VC Raghuram, O Khattab, J Hirschberg, Z Yu 

**NAACL 2025** | [paper](https://arxiv.org/abs/2410.17127)

**Grounding by Trying: LLMs with Reinforcement Learning-Enhanced Retrieval**

 S Hsu, O Khattab, C Finn, A Sharma 

**ICLR 2025** | [paper](https://arxiv.org/abs/2410.23214)

**ColBERT-serve: Efficient Multi-Stage Memory-Mapped Scoring**

 K Huang, T Venkatesh, U Dingankar, …, O Khattab, S Sarup, K Santhanam 

**ECIR 2025** | [paper](https://www.antoniomallia.it/uploads/ECIR25c.pdf)

**Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations**

 R Wang, P Wirawarn, K Lam, O Khattab, D Demszky 

**EMNLP 2024 Findings** | [paper](https://arxiv.org/abs/2411.07598)

**Fine-Tuning and Prompt Optimization: Two Great Steps that Work Better Together**

 D Soylu, C Potts, O Khattab

**EMNLP 2024** | [paper](https://arxiv.org/abs/2407.10930)

**Prompts as Auto-Optimized Training Hyperparameters: Training Best-in-Class IR Models from Scratch with 10 Gold Labels**

 J Xian, S Samuel, F Khoubsirat, R Pradeep, …, A Sil, C Potts, O Khattab

**Tech Report 2024** | [paper](https://arxiv.org/abs/2406.11706)

**Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs**

 K Opsahl-Ong, M Ryan, J Purtell, D Broman, C Potts, M Zaharia, O Khattab

**EMNLP 2024** | [paper](https://arxiv.org/abs/2406.11695)

**Backtracing: Retrieving the Cause of the Query**

 R Wang, P Wirawarn, O Khattab, N Goodman, D Demszky 

**EACL Findings 2024** | [paper](https://arxiv.org/abs/2403.03956)

**Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models**

 Y Shao, Y Jiang, T Kanell, P Xu, O Khattab, M Lam 

**NAACL 2024** | [paper](https://arxiv.org/abs/2402.14207)

**ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems**

 J Saad-Falcon, O Khattab, M Zaharia, C Potts

**NAACL 2024** | [paper](https://arxiv.org/abs/2311.09476)

**In-Context Learning for Extreme Multi-Label Classification**

 K D’Oosterlinck, O Khattab, F Remy, T Demeester, C Develder, C Potts 

**Preprint 2024** | [paper](https://arxiv.org/abs/2401.12178)

**Building Efficient and Effective OpenQA Systems for Low-Resource Languages**

 E Budur, R Özçelik, D Soylu, O Khattab, T Güngör, C Potts 

**Preprint 2024** | [paper](https://arxiv.org/abs/2401.03590)

**DSPy Assertions: Computational Constraints for Self-Refining Language Model Pipelines**

 A Singhvi, M Shetty, S Tan, C Potts, K Sen, M Zaharia, O Khattab

**Preprint 2023** | [paper](https://arxiv.org/abs/2312.13382)

**DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines**

O Khattab, A Singhvi, P Maheshwari, Z Zhang, K Santhanam, S Vardhamanan, S Haq, A Sharma, T Joshi, H Moazam, H Miller, M Zaharia, C Potts

**ICLR 2024 (Spotlight)** | [paper](https://arxiv.org/abs/2310.03714)

**Image and Data Mining in Reticular Chemistry Using GPT-4V**

 Z Zheng, Z He, O Khattab, N Rampal, M Zaharia, C Borgs, J Chayes, O Yaghi 

**Digital Discovery 2024** | [paper](https://omarkhattab.com/[https://arxiv.org/abs/2312.05468](https://pubs.rsc.org/en/content/articlelanding/2024/dd/d3dd00239j))

**UDAPDR: Unsupervised Domain Adaptation via LLM Prompting and Distillation of Rerankers**

 J Saad-Falcon, O Khattab, K Santhanam, R Florian, M Franz, S Roukos, A Sil, M Sultan, C Potts

**EMNLP 2023** | [paper](https://arxiv.org/abs/2303.00807)

**Resources and Evaluations for Multi-Distribution Dense Information Retrieval**

 S Chatterjee, O Khattab, S Arora

**SIGIR REML 2023** | [paper](https://arxiv.org/abs/2306.12601)

**Moving Beyond Downstream Task Accuracy for Information Retrieval Benchmarking**

 K Santhanam, J Saad-Falcon, M Franz, O Khattab, A Sil, R Florian, S Roukos, A Sil, M Sultan, M Zaharia, C Potts

**ACL 2023 Findings** | [paper](https://arxiv.org/abs/2212.01340)

**Holistic evaluation of language models**

 P Liang, R Bommasani, T Lee, D Tsipras, D Soylu, …, O Khattab, …, Y Zhang, Y Koreeda

**TMLR 2023** | [paper](https://arxiv.org/abs/2211.09110)

_Note: This is a multi-component, 50-author project. O Khattab directed the Information Retrieval evaluation._

**Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP**

O. Khattab, K. Santhanam, X. Li, P. Liang, C. Potts, M. Zaharia 

**ArXiv 2022** | [paper](https://arxiv.org/abs/2212.14024) | [code](https://github.com/stanfordnlp/dsp/)

**PLAID: An Efficient Engine for Late Interaction Retrieval**

 K. Santhanam*****, O. Khattab*****, C. Potts, M. Zaharia 

**CIKM 2022** | [paper](https://arxiv.org/abs/2205.09707) | (***** denotes co-first authors)

**ColBERTv2: Effective and Efficient Retrieval via Lightweight Late Interaction**

 K. Santhanam*****, O. Khattab*****, J. Saad-Falcon, C. Potts, M. Zaharia 

**NAACL 2022** | [paper](https://arxiv.org/abs/2112.01488) | (***** denotes co-first authors)

**Introducing Neural Bag of Whole-Words with ColBERTer: Contextualized Late Interactions using Enhanced Reduction**

 S. Hofstätter, O. Khattab, S. Althammer, M. Sertkan, A. Hanbury 

**CIKM 2022** | [paper](https://arxiv.org/abs/2203.13088)

**Hindsight: Posterior-guided Training of Retrievers for Improved Open-Ended Generation**

 A. Paranjape, O. Khattab, C. Potts, M. Zaharia, Christopher D. Manning 

**ICLR 2022** | [preprint](https://arxiv.org/abs/2110.07752)

**Baleen: Robust Multi-Hop Reasoning at Scale via Condensed Retrieval**

O. Khattab, C. Potts, M. Zaharia 

**NeurIPS 2021 (Spotlight)** | [preprint](https://arxiv.org/abs/2101.00436) | [HoVer leaderboard entry](https://hover-nlp.github.io/)

**On the Opportunities and Risks of Foundation Models**

 Stanford’s Center for Research on Foundation Models (CRFM), with 113 co-authors 

 Contributions to: Systems, Modeling, and Reasoning & Search 

**ArXiv 2021** | [paper](https://arxiv.org/abs/2108.07258)

**Relevance-guided Supervision for OpenQA with ColBERT**

O. Khattab, C. Potts, M. Zaharia 

**TACL 2021** | [paper](https://arxiv.org/abs/2007.00814)

**Learning Passage Impacts for Inverted Indexes**

 A. Mallia, O. Khattab, N. Tonellotto, T. Suel 

**SIGIR 2021** (short) | [paper](https://arxiv.org/abs/2104.12016)

**ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT**

O. Khattab and M. Zaharia 

**SIGIR 2020** | [paper](https://arxiv.org/abs/2004.12832) | [code](https://github.com/stanford-futuredata/ColBERT)

**Finding the Best of Both Worlds: Faster and More Robust Top-k Document Retrieval**

O. Khattab, M. Hammoud, and T. Elsayed

**SIGIR 2020** | [paper](https://dl.acm.org/doi/10.1145/3397271.3401076)

**PolyHJ: A Polymorphic Main-Memory Hash Join Paradigm for Multi-Core Machines**

O. Khattab, M. Hammoud, and O. Shekfeh

**CIKM 2018** | [paper](https://dl.acm.org/doi/10.1145/3269206.3271680) | [code](https://github.com/cmuq-ccl/PolyHJ)

**LA3: A Scalable Link- and Locality-Aware Linear Algebra-Based Graph Analytics System**

 Y. Ahmad, O. Khattab, A. Malik, A. Musleh, M. Hammoud, M. Kutlu, M. Shehata, T. Elsayed

**VLDB 2018** | [paper](http://www.vldb.org/pvldb/vol11/p920-ahmad.pdf) | [code](https://github.com/cmuq-ccl/LA3)

* * *

Blog Posts
==========

**On Impactful AI Research**

O. Khattab | [post](https://github.com/okhat/blog/blob/main/2024.09.impact.md)

**The Shift from Models to Compound AI Systems**

 M. Zaharia, O. Khattab, L. Chen, J. Q. Davis, H. Miller, C. Potts, J. Zou, M. Carbin, J. Frankle, N. Rao, A. Ghodsi 

**Berkeley Artificial Intelligence Research** | [post](https://bair.berkeley.edu/blog/2024/02/18/compound-ai-systems/)

**A Guide to Large Language Model Abstractions**

 P. Y. Zhong, H. He, O. Khattab, C. Potts, M. Zaharia , H, Miller 

**Two Sigma Articles** | [post](https://www.twosigma.com/articles/a-guide-to-large-language-model-abstractions/)

**Building Scalable, Explainable, and Adaptive NLP Models with Retrieval**

O. Khattab, C. Potts, M. Zaharia 

**Stanford AI Lab (SAIL) blog** | [post](http://ai.stanford.edu/blog/retrieval-based-NLP/)

**A moderate proposal for radically better AI-powered Web search. Stanford HAI blog.**

O. Khattab, C. Potts, M. Zaharia 

**Stanford HAI blog** | [post](https://hai.stanford.edu/news/moderate-proposal-radically-better-ai-powered-web-search)

Last Update: July 2025

Theme by [orderedlist](https://github.com/orderedlist) | [Favicon Source](https://www.favicon-generator.org/search/---/Ok)
