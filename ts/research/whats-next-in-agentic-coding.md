---
title: "Here's What's Next in Agentic Coding"
url: https://seconds0.substack.com/p/heres-whats-next-in-agentic-coding
date_fetched: 2026-02-16
author: Seconds
---

# Here's What's Next in Agentic Coding

**Author:** Seconds
**Date:** November 11, 2025
**Publication:** Seconds_0 Substack

## Overview

This comprehensive article explores the near-term evolution of coding harnesses -- the orchestration layers wrapping around coding LLMs. The central thesis emphasizes that "context management is everything," arguing that extracting maximum value from existing models depends less on model capability and more on intelligent context curation.

## I. Context Management Fundamentals

The author positions context management as the critical bottleneck. A harness must accomplish dual objectives: injecting relevant context while filtering out noise. The piece notes that "there's a billion dollars inside of that model," accessible only through strategic prompt engineering and context optimization.

## II. Plan Mode Revolution

Plan Mode represents a major evolution from manual markdown-based planning. The trend accelerated after Claude Code's launch, with Cursor subsequently adopting similar features. The author advocates for more sophisticated planning implementations -- moving beyond basic decomposition toward comprehensive, multi-page strategies that include architecture diagrams, documentation references, and coding standards.

## III. Context Management Details

**Search Integration:** The article discusses combining grep-based and embedding-based search. Cursor's research found this hybrid approach both more effective and valuable for reinforcement learning pipelines.

**Documentation Strategy:** Context7 MCP exemplifies how indexed documentation should be accessible on-demand. The author suggests models should know their knowledge cutoff dates to encourage appropriate information retrieval.

**Rules and Skills:** Conditional rules -- triggered by file types or intelligent evaluation -- enable context-appropriate prompts without polluting the general context space.

**Portable Configurations:** Power users struggle with configuration portability across repositories. The author envisions GitHub-based configuration repositories, similar to dotfiles systems.

## IV. Multiagent Orchestration

**Best of N:** Multiple parallel generation and synthesis improves output quality, though at increased token costs. The technique proves particularly valuable for less capable models.

**Mixed Model Strategies:** Frontier models handle planning while specialized, economical models execute implementation. This approach achieves comparable quality at substantially reduced cost and latency.

**Subagents:** Smaller dispatched agents provide parallelization, context isolation, and prompt customization. Current implementations remain "tame," with significant untapped potential.

**Captain's Chair:** The author envisions a long-running primary agent coordinating multiple specialized subagents, presented through a unified chat interface with a sidebar showing active agent activity.

## V. Quality Loop

**Critic and Self-Review:** Automatic review agents identify errors, edge cases, and complexity reduction opportunities. Jules demonstrates this pattern effectively.

**Self-Improvement:** Harnesses should periodically retrospect and recommend configuration enhancements. The author suggests agents could autonomously optimize rules, hooks, and tools based on session analysis.

**Memory Systems:** Future implementations will externalize agent memory separately from context, enabling agents to manage their own context through memory tooling rather than relying solely on prompt engineering.

## VI. Three Divergent User Futures

**Vibe Coders:** Require minimal technical knowledge, relying on tools like Loveable or Bolt for one-shot web generation with minimal errors.

**Commanders:** Power users dispatching numerous parallel agents, focusing on results review rather than configuration optimization.

**Synchronous Developers:** Work near or outside agent capability boundaries, preferring discussion with models while maintaining manual code control.

## Conclusion

The article charts an "eye-wateringly meteoric" development trajectory. From November 2024 through November 2025, eleven significant paradigm shifts occurred. The author argues 2026 represents the convergence point where polished harnesses meet new-generation models, enabling unprecedented code generation capabilities.

The four pillars of Q1-Q2 2026 roadmaps are:

1. Manage user context strategically
2. Leverage model intelligence for self-improvement
3. Customize tools to specific users
4. Parallelize development speed

The recurring refrain underscores the entire analysis: context management remains the fundamental lever for extracting value from coding AI.
