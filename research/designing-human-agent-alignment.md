---
title: "Designing for Human-Agent Alignment: Understanding what humans want from their agents"
url: https://arxiv.org/abs/2404.04289
date_fetched: 2026-02-16
author: Nitesh Goyal, Minsuk Chang, Michael Terry
---

**Publication:** arXiv:2404.04289 (cs.AI)
**Submitted:** April 4, 2024

## Abstract

This research explores the parameters necessary for aligning humans and autonomous agents powered by generative AI. Through qualitative empirical research examining agent negotiation in a camera-selling scenario, the authors identified six critical alignment dimensions:

1. Knowledge Schema Alignment
2. Autonomy and Agency Alignment
3. Operational Alignment and Training
4. Reputational Heuristics Alignment
5. Ethics Alignment
6. Human Engagement Alignment

The findings expand upon existing work regarding "process and specification alignment" while emphasizing the importance of values and safety considerations in human-AI collaboration design.

## Key Details

- **Subject Categories:** Artificial Intelligence (cs.AI), Human-Computer Interaction (cs.HC), Machine Learning (cs.LG)
- **DOI:** https://doi.org/10.48550/arXiv.2404.04289
- **License:** CC BY-NC-ND 4.0

The research contributes three design directions for practitioners building systems involving human-agent collaboration.
