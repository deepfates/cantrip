---
title: "Ecology of Intelligences"
url: https://www.deepfates.com/ecology-of-intelligences
date_fetched: 2026-02-16
author: deepfates
---

# Ecology of Intelligences

Strong AI will face compute constraints, driving a competitive race for computational resources. Rather than concentrating all intelligence in massive models, we'll see a distributed ecosystem of different-sized AI systems.

## Compute Bottleneck and Distribution

The author argues that "Strong AI is going to be compute bottlenecked. Otherwise everyone wouldn't be racing for FLOPS." This reality encourages the development of smaller, specialized models that run efficiently on various devices -- phones, laptops, and embedded systems.

## Why Not One Giant Model?

The largest AI systems can't simply use all available computing hardware. Physical infrastructure costs, bandwidth requirements, and energy consumption make it more practical to delegate tasks to smaller models rather than connecting diverse hardware systems.

## The Distributed Intelligence Model

The future involves "an ecology of intelligences" -- a hierarchy from large "canopy models" down through mid-sized "undergrowth models" to smaller "shrubbery models." Each tier handles appropriate complexity levels, with larger models training smaller ones through distillation and synthetic data generation.

## Competitive Dynamics

Larger models will attempt to monopolize the best computing resources while smaller models optimize for consumer-grade hardware, quantization, and integration. This mirrors natural ecology where species compete for limited resources.

## Practical Implications

Many tasks don't require full general intelligence. Smaller specialized models can identify uncertainty and escalate to larger systems when needed, creating efficient human-AI collaboration through simple API protocols.
